{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "463c63bc-98e3-4b29-990a-edf91174f9b5",
   "metadata": {},
   "source": [
    "# Comments\n",
    "\n",
    "1.\n",
    "    a) Easy negative is parsed from a summary of a random Wikipedia page. It is pretty slow (1 second per question). That is why I play only with the first ten entries of the dataset. However, one can run this code on multiple cores in parallel, e.g. by slicing the input dataset and parsing the slice names from the command line.\n",
    "\n",
    "    b) I'm not sure I understand this task. I iterate over your dataset and separate positive, hard negative, and easy negative in three output datasets. Also, to ensure that no combination of contexts appears more than once, I use only a single hard negative context per question. Is that what you mean?\n",
    "\n",
    "    As for efficiency, the algorithm's time and space complexity is O(n), where n is the dataset length. The space complexity can be improved by modifying the input data set in place. Is this the efficiency you expected?\n",
    "\n",
    "3. I save the datasets in context_qa format. My output dataset is split into positive, hard negative, and easy negative contexts as separate files. If you need all the contexts within a single file, I can easily combine them.\n",
    "\n",
    "4. I cleaned up titles from contexts, i.e. everything before the latest \"=\\n\" per string. I also removed some special characters such as \"\\n\" and \"\\u00a0\". Apart from that, one should ensure that the model recognises umlauts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ed4515",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wikipedia\n",
    "wikipedia.set_lang(\"de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a383a24b-75c6-4c0d-955d-458ff7899077",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to generate easy negatives\n",
    "def generate_easy_negative():\n",
    "    random_page_title = wikipedia.random(1)\n",
    "    try:\n",
    "        random_page_summary = wikipedia.summary(random_page_title)\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        random_page_summary = generate_easy_negative()    \n",
    "    return random_page_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8044be3a-9450-4e74-a0eb-6203a1508660",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions to clean up context strings\n",
    "def cleanup_ctx_title(str):\n",
    "    idx = str.rfind(\"=\\n\")+2\n",
    "    str = str[idx:]\n",
    "    return str\n",
    "    \n",
    "def cleanup_context(str):\n",
    "    str = cleanup_ctx_title(str)\n",
    "    str = str.replace('\\n', ' ')\n",
    "    str = str.replace('\\u00a0', ' ')\n",
    "    return str\n",
    "\n",
    "def cleanup_context_list(lst):\n",
    "    for i in range(len(lst)):\n",
    "        lst[i] = cleanup_context(lst[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0847e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading dataset\n",
    "\n",
    "input = 'https://huggingface.co/datasets/DiscoResearch/germanrag/resolve/main/germanrag.jsonl'\n",
    "df = pd.read_json(input, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8de4ed-5dc4-4248-9a5e-c1304be48527",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Taking a subset to play with\n",
    "df = df.iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425f75fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Iteration over the dataset and creation of the \n",
    "### dataset_positive, dataset_neg_easy and dataset_neg_hard.\n",
    "\n",
    "dataset_positive = []\n",
    "dataset_neg_easy = []\n",
    "dataset_neg_hard = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    contexts = row['contexts'][:]\n",
    "    question = row['question']\n",
    "    answer = row['answer']\n",
    "    idx = row['positive_ctx_idx']\n",
    "\n",
    "    # Clean up junk characters from contexts\n",
    "    cleanup_context_list(contexts)\n",
    "    \n",
    "    # Pop a positive context\n",
    "    ctx_positive = \"\"\n",
    "    if idx >= 0:\n",
    "        ctx_positive = contexts.pop(idx)\n",
    "\n",
    "    # Generate an easy negative context\n",
    "    ctx_neg_easy = generate_easy_negative()\n",
    "    answer_neg_easy = \"Ihre Anfrage enthält keine erforderlichen Informationen\"\n",
    "    \n",
    "    # Take a single hard negative context.\n",
    "    ctx_neg_hard = \"\"\n",
    "    if contexts:\n",
    "        ctx_neg_hard = contexts[0]\n",
    "    answer_neg_hard = \"Ihre Anfrage enthält nicht genügend Informationen\"\n",
    "\n",
    "    dataset_positive.append({\"context\":ctx_positive,\"question\":question,\"answer\":answer})\n",
    "    dataset_neg_easy.append({\"context\":ctx_neg_easy,\"question\":question,\"answer\":answer_neg_easy})\n",
    "    dataset_neg_hard.append({\"context\":ctx_neg_hard,\"question\":question,\"answer\":answer_neg_hard})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d45dc3-2ef6-4d0d-9fd4-5a9ea3e8f4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make datasets as pandas frames\n",
    "df_positive = pd.DataFrame(dataset_positive)\n",
    "df_neg_easy = pd.DataFrame(dataset_positive)\n",
    "df_neg_hard = pd.DataFrame(dataset_positive)\n",
    "\n",
    "# Save to jsonl\n",
    "df_positive.to_json(\"positive.jsonl\",orient='records',lines=True)\n",
    "df_neg_easy.to_json(\"neg_easy.jsonl\",orient='records',lines=True)\n",
    "df_neg_hard.to_json(\"neg_hard.jsonl\",orient='records',lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
